{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc890dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\envs\\transformer_git\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from optuna.samplers import TPESampler\n",
    "import sqlalchemy\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_squared_error,mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from xgboost import XGBClassifier\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Ridge  # 使用 Ridge 回归代替逻辑回归\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "from scipy.stats import entropy\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 支持中文字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号 '-' 显示问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27b43f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "# 忽略所有PerformanceWarning\n",
    "warnings.simplefilter(\"ignore\", category=PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee76cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\wiki_embeding_cluster\\output_wiki_vectorized_sequences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9239d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['商品名称',  '关联店铺', '商品分类', '商品品牌', '浏览量', '视频数','抖音号','商品综合信息'])\n",
    "df['佣金率'] =df['佣金率'].str.replace('%', '').astype(float) / 100\n",
    "df = df.dropna()\n",
    "df.sort_values(by='佣金率')\n",
    "\n",
    "df['转化率_1'] = df['转化率_编码'].apply(lambda x: 3 if x >= 3 else x)\n",
    "df['转化率_1'].value_counts()\n",
    "\n",
    "df = df.drop(columns=['转化率_编码'])\n",
    "\n",
    "\n",
    "df = df.drop(columns=['视频销售额_编码', '视频销量_编码','点赞', '评论', '分享', '收藏',])\n",
    "df['带货视频'] = df['带货视频'].apply(lambda x: 1 if x>0  else x)\n",
    "\n",
    "\n",
    "df['销售均价最大差值'] = df['销售均价最大值'] - df['销售均价最小值']\n",
    "df['销售均价'] = (df['销售均价最大值'] + df['销售均价最小值']) /2\n",
    "\n",
    "df['商品价格最大差值'] = df['商品价格最大值'] - df['商品价格最小值']\n",
    "df['商品价格中位数'] = (df['商品价格最大值'] + df['商品价格最小值']) /2\n",
    "\n",
    "df = df.drop(columns=['销售均价最大值','销售均价最小值','商品价格最大值','商品价格最小值'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e4c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['销售均价_groupby_cluster'] = df.groupby(by = 'cluster_similarity')['销售均价'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "df['商品价格中位数_groupby_cluster'] = df.groupby(by = 'cluster_similarity')['商品价格中位数'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# 计算每个 cluster_label 内的分位数并分类\n",
    "def assign_percentile_group(x):\n",
    "    quantiles = [0, 0.4, 0.7, 0.9, 1.0]\n",
    "    quantile_labels = [ 'per60-100', 'per30-60', 'per10-30','per0-10']\n",
    "    q_bins = np.quantile(x, quantiles)  # 计算当前组的分位数边界\n",
    "    return pd.cut(x, bins=q_bins, labels=quantile_labels, include_lowest=True)\n",
    "\n",
    "df['销售均价分位数'] = df.groupby('cluster_similarity')['销售均价'].transform(assign_percentile_group)\n",
    "\n",
    "df = df.drop(columns = ['销售均价'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e1c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['转化率_1'])\n",
    "y = df['转化率_1']\n",
    "# 拆分训练集和测试集（70%训练，30%测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "train = X_train.copy()\n",
    "train['转化率_1'] = y_train\n",
    "\n",
    "test = X_test.copy()\n",
    "\n",
    "target = '转化率_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caeb1828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+-----------+-----------------+----------------+\n",
      "|          Column Name           | Data Type | Train Missing % | Test Missing % |\n",
      "+--------------------------------+-----------+-----------------+----------------+\n",
      "|             佣金率             |  float64  |       0.0       |      0.0       |\n",
      "|            带货视频            |  float64  |       0.0       |      0.0       |\n",
      "|            带货直播            |  float64  |       0.0       |      0.0       |\n",
      "|             粉丝数             |   int64   |       0.0       |      0.0       |\n",
      "|          销售额_编码           |   int64   |       0.0       |      0.0       |\n",
      "|           销量_编码            |   int64   |       0.0       |      0.0       |\n",
      "|        直播销售额_编码         |   int64   |       0.0       |      0.0       |\n",
      "|         直播销量_编码          |   int64   |       0.0       |      0.0       |\n",
      "|          上架距今(天)          |   int64   |       0.0       |      0.0       |\n",
      "|            视频热度            |  float64  |       0.0       |      0.0       |\n",
      "|             互动量             |  float64  |       0.0       |      0.0       |\n",
      "|             互动率             |  float64  |       0.0       |      0.0       |\n",
      "|       cluster_similarity       |   int64   |       0.0       |      0.0       |\n",
      "|         cluster_kmeans         |   int64   |       0.0       |      0.0       |\n",
      "|         cluster_dbscan         |   int64   |       0.0       |      0.0       |\n",
      "|        cluster_hdbscan         |   int64   |       0.0       |      0.0       |\n",
      "|             tsne_x             |  float64  |       0.0       |      0.0       |\n",
      "|             tsne_y             |  float64  |       0.0       |      0.0       |\n",
      "|        销售均价最大差值        |  float64  |       0.0       |      0.0       |\n",
      "|        商品价格最大差值        |   int64   |       0.0       |      0.0       |\n",
      "|         商品价格中位数         |  float64  |       0.0       |      0.0       |\n",
      "|    销售均价_groupby_cluster    |  float64  |       0.0       |      0.0       |\n",
      "| 商品价格中位数_groupby_cluster |  float64  |       0.0       |      0.0       |\n",
      "|         销售均价分位数         |  category |       0.0       |      0.0       |\n",
      "+--------------------------------+-----------+-----------------+----------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Column Name', 'Data Type', 'Train Missing %', 'Test Missing %']\n",
    "for column in X_train.columns:\n",
    "    data_type = str(train[column].dtype)\n",
    "    non_null_count_train  = 100 - train[column].count()/train.shape[0] * 100\n",
    "    if column != target:\n",
    "        non_null_count_test = 100 - test[column].count()/test.shape[0] * 100\n",
    "    else:\n",
    "        non_null_count_test = 'NA'\n",
    "    table.add_row([column,data_type,non_null_count_train,non_null_count_test])\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6dec7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def min_max_scaler(train, test, column):\n",
    "    sc=MinMaxScaler()\n",
    "    \n",
    "    max_val=max(train[column].max(),test[column].max())\n",
    "    min_val=min(train[column].min(),test[column].min())\n",
    "\n",
    "    train[column]=(train[column]-min_val)/(max_val-min_val)\n",
    "    test[column]=(test[column]-min_val)/(max_val-min_val)\n",
    "    \n",
    "    return train,test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77987ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y1,y2):\n",
    "    return(np.sqrt(mean_squared_error(np.array(y1),np.array(y2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d5739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global y_unique\n",
    "y_unique=train[target].unique()\n",
    "# y_unique_log=np.log1p(train[target]).unique()\n",
    "\n",
    "def nearest(y_predicted):\n",
    "    \n",
    "    y_original=y_unique\n",
    "    modified_prediction = np.zeros_like(y_predicted)\n",
    "\n",
    "    for i, y_pred in enumerate(y_predicted):\n",
    "        nearest_value = min(y_original, key=lambda x: abs(x - y_pred))\n",
    "        modified_prediction[i] = nearest_value\n",
    "\n",
    "    return modified_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "831b99a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['佣金率',\n",
       " '带货直播',\n",
       " '粉丝数',\n",
       " '销售额_编码',\n",
       " '销量_编码',\n",
       " '直播销售额_编码',\n",
       " '直播销量_编码',\n",
       " '上架距今(天)',\n",
       " '视频热度',\n",
       " '互动量',\n",
       " '互动率',\n",
       " 'tsne_x',\n",
       " 'tsne_y',\n",
       " '商品价格最大差值',\n",
       " '商品价格中位数']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols = [f for f in X.columns if train[f].dtype != 'O' and train[f].nunique()>10 and 'groupby' not in f]\n",
    "cont_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedcd5cf",
   "metadata": {},
   "source": [
    "## 1 Numerical Transformations\n",
    "\n",
    "<font size=\"3\">We're going to see what transformation works better for each feature and select them, the idea is to compress the data. There could be situations where you will have to stretch the data. These are the methods applied:</font>\n",
    "\n",
    "1. **Log Transformation**: <font size=\"3\">This transformation involves taking the logarithm of each data point. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n",
    "                y = log(x)\n",
    "\n",
    "2. **Square Root Transformation**: <font size=\"3\">This transformation involves taking the square root of each data point. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n",
    "                y = sqrt(x)\n",
    "\n",
    "3. **Box-Cox Transformation**: <font size=\"3\">This transformation is a family of power transformations that includes the log and square root transformations as special cases. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n",
    "                y = [(x^lambda) - 1] / lambda if lambda != 0\n",
    "                y = log(x) if lambda = 0\n",
    "\n",
    "4. **Yeo-Johnson Transformation**: <font size=\"3\">This transformation is similar to the Box-Cox transformation, but it can be applied to both positive and negative values. It is useful when the data is highly skewed and the variance increases with the mean.</font>\n",
    "                y = [(|x|^lambda) - 1] / lambda if x >= 0, lambda != 0\n",
    "                y = log(|x|) if x >= 0, lambda = 0\n",
    "                y = -[(|x|^lambda) - 1] / lambda if x < 0, lambda != 2\n",
    "                y = -log(|x|) if x < 0, lambda = 2\n",
    "\n",
    "5. **Power Transformation**: <font size=\"3\">This transformation involves raising each data point to a power. It is useful when the data is highly skewed and the variance increases with the mean. The power can be any value, and is often determined using statistical methods such as the Box-Cox or Yeo-Johnson transformations.</font>\n",
    "                y = [(x^lambda) - 1] / lambda if method = \"box-cox\" and lambda != 0\n",
    "                y = log(x) if method = \"box-cox\" and lambda = 0\n",
    "                y = [(x + 1)^lambda - 1] / lambda if method = \"yeo-johnson\" and x >= 0, lambda != 0\n",
    "                y = log(x + 1) if method = \"yeo-johnson\" and x >= 0, lambda = 0\n",
    "                y = [-(|x| + 1)^lambda - 1] / lambda if method = \"yeo-johnson\" and x < 0, lambda != 2\n",
    "                y = -log(|x| + 1) if method = \"yeo-johnson\" and x < 0, lambda = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70cf0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer,FunctionTransformer\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "sc=MinMaxScaler()\n",
    "\n",
    "global unimportant_features\n",
    "global overall_best_score\n",
    "global overall_best_col\n",
    "unimportant_features=[]\n",
    "overall_best_score=1e5\n",
    "overall_best_col='none'\n",
    "\n",
    "def transformer(train, test,cont_cols, target):\n",
    "    '''\n",
    "    Algorithm applies multiples transformations on selected columns and finds the best transformation using a single variable model performance\n",
    "    '''\n",
    "    global unimportant_features\n",
    "    global overall_best_score\n",
    "    global overall_best_col\n",
    "    train_copy = train.copy()\n",
    "    test_copy = test.copy()\n",
    "    print(train_copy.shape)\n",
    "    print(test_copy.shape)\n",
    "#     train_copy.fillna(train_copy.mean(), inplace=True)\n",
    "#     test_copy.fillna(test_copy.mean(), inplace=True)\n",
    "    \n",
    "    \n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Feature', 'Original RMSLE', 'Transformation', 'Tranformed RMSLE']\n",
    "\n",
    "    for col in cont_cols:\n",
    "        \n",
    "        # 处理负值或零值\n",
    "        if (train_copy[col] <= 0).any():  # 检查是否存在负值或零值\n",
    "            print(f\"Negative or zero values found in {col}, applying correction...\")\n",
    "            # 使用clip方法将小于等于0的值设置为一个很小的正数（例如1e-5）\n",
    "            train_copy[col] = train_copy[col].clip(lower=1e-3)\n",
    "            test_copy[col] = test_copy[col].clip(lower=1e-3)\n",
    "        \n",
    "        # MinMax Scaling\n",
    "        train_copy, test_copy = min_max_scaler(train_copy, test_copy, col)\n",
    "        \n",
    "        # 清理之前可能存在的列\n",
    "        for c in [\"log_\" + col, \"sqrt_\" + col, \"bx_cx_\" + col, \"y_J_\" + col, \"log_sqrt\" + col, \"pow_\" + col, \"pow2_\" + col]:\n",
    "            if c in train_copy.columns:\n",
    "                train_copy = train_copy.drop(columns=[c])\n",
    "\n",
    "        # Log Transformation after MinMax Scaling\n",
    "        train_copy[\"log_\" + col] = np.log1p(train_copy[col])\n",
    "        test_copy[\"log_\" + col] = np.log1p(test_copy[col])\n",
    "\n",
    "        # Square Root Transformation\n",
    "        train_copy[\"sqrt_\" + col] = np.sqrt(train_copy[col])\n",
    "        test_copy[\"sqrt_\" + col] = np.sqrt(test_copy[col])\n",
    "\n",
    "        # Box-Cox Transformation\n",
    "        epsilon = 1e-3\n",
    "        transformer = PowerTransformer(method='box-cox')\n",
    "        train_copy[\"bx_cx_\" + col] = transformer.fit_transform(train_copy[[col]] + epsilon)\n",
    "        test_copy[\"bx_cx_\" + col] = transformer.transform(test_copy[[col]] + epsilon)\n",
    "\n",
    "        # Yeo-Johnson Transformation\n",
    "        transformer = PowerTransformer(method='yeo-johnson')\n",
    "        train_copy[\"y_J_\" + col] = transformer.fit_transform(train_copy[[col]])\n",
    "        test_copy[\"y_J_\" + col] = transformer.transform(test_copy[[col]])\n",
    "\n",
    "        # Power Transformation, 0.25\n",
    "        power_transform = lambda x: np.power(x + 1 - np.min(x), 0.25)\n",
    "        transformer = FunctionTransformer(power_transform)\n",
    "        train_copy[\"pow_\" + col] = transformer.fit_transform(train_copy[[col]])\n",
    "        test_copy[\"pow_\" + col] = transformer.transform(test_copy[[col]])\n",
    "\n",
    "        # Power Transformation, 2\n",
    "        power_transform = lambda x: np.power(x + 1 - np.min(x), 2)\n",
    "        transformer = FunctionTransformer(power_transform)\n",
    "        train_copy[\"pow2_\" + col] = transformer.fit_transform(train_copy[[col]])\n",
    "        test_copy[\"pow2_\" + col] = transformer.transform(test_copy[[col]])\n",
    "\n",
    "        # Log of Square Root Transformation\n",
    "        train_copy[\"log_sqrt\" + col] = np.log1p(train_copy[\"sqrt_\" + col])\n",
    "        test_copy[\"log_sqrt\" + col] = np.log1p(test_copy[\"sqrt_\" + col])\n",
    "\n",
    "        temp_cols = [col, \"log_\" + col, \"sqrt_\" + col, \"bx_cx_\" + col, \"y_J_\" + col, \"pow_\" + col, \"pow2_\" + col, \"log_sqrt\" + col]\n",
    "\n",
    "        if train_copy[temp_cols].isnull().any().any():\n",
    "            print(f\"NaN values found in {temp_cols} after transformations\")\n",
    "            train_copy[temp_cols] = train_copy[temp_cols].fillna(train_copy[temp_cols].median())\n",
    "            test_copy[temp_cols] = test_copy[temp_cols].fillna(test_copy[temp_cols].median())\n",
    "\n",
    "#         pca = TruncatedSVD(n_components=1)\n",
    "#         x_pca_train = pca.fit_transform(train_copy[temp_cols])\n",
    "#         x_pca_test = pca.transform(test_copy[temp_cols])\n",
    "#         x_pca_train = pd.DataFrame(x_pca_train, columns=[col + \"_pca_comb\"])\n",
    "#         x_pca_test = pd.DataFrame(x_pca_test, columns=[col + \"_pca_comb\"])\n",
    "#         temp_cols.append(col + \"_pca_comb\")\n",
    "\n",
    "#         test_copy = test_copy.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#         train_copy = pd.concat([train_copy, x_pca_train], axis='columns')\n",
    "#         test_copy = pd.concat([test_copy, x_pca_test], axis='columns')\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rmse_scores = []\n",
    "        \n",
    "        for f in temp_cols:\n",
    "            \n",
    "            X = train_copy[[f]].values\n",
    "            y = train_copy[target].values\n",
    "            \n",
    "            rmses = []\n",
    "            for train_idx, val_idx in kf.split(X, y):\n",
    "                X_train, y_train = X[train_idx], y[train_idx]\n",
    "                x_val, y_val = X[val_idx], y[val_idx]\n",
    "                model=LinearRegression()\n",
    "                model.fit(X_train,y_train)\n",
    "                y_pred=nearest(model.predict(x_val))\n",
    "                rmses.append(rmse(y_val,y_pred))\n",
    "                \n",
    "            rmse_scores.append((f,np.mean(rmses)))\n",
    "            \n",
    "            if overall_best_score > np.mean(rmses):\n",
    "                overall_best_score = np.mean(rmses)\n",
    "                overall_best_col = f\n",
    "\n",
    "            if f == col:\n",
    "                orig_rmse = np.mean(rmses)\n",
    "                \n",
    "        best_col, best_rmse = sorted(rmse_scores, key=lambda x: x[1], reverse=False)[0]\n",
    "        cols_to_drop = [f for f in temp_cols if f != best_col]\n",
    "#         final_selection = [f for f in temp_cols if f not in cols_to_drop]\n",
    "        \n",
    "        if cols_to_drop:\n",
    "            unimportant_features = unimportant_features + cols_to_drop\n",
    "        table.add_row([col,orig_rmse,best_col ,best_rmse])\n",
    "    print(table)   \n",
    "    print(\"overall best CV RMSLE score: \",overall_best_score)\n",
    "    return train_copy, test_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6953827e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20081, 25)\n",
      "(3544, 24)\n",
      "Negative or zero values found in 佣金率, applying correction...\n",
      "Negative or zero values found in 带货直播, applying correction...\n",
      "Negative or zero values found in 销售额_编码, applying correction...\n",
      "Negative or zero values found in 销量_编码, applying correction...\n",
      "Negative or zero values found in 直播销售额_编码, applying correction...\n",
      "Negative or zero values found in 直播销量_编码, applying correction...\n",
      "Negative or zero values found in tsne_x, applying correction...\n",
      "Negative or zero values found in tsne_y, applying correction...\n",
      "Negative or zero values found in 商品价格最大差值, applying correction...\n",
      "Negative or zero values found in 商品价格中位数, applying correction...\n",
      "+------------------+--------------------+----------------------+--------------------+\n",
      "|     Feature      |   Original RMSLE   |    Transformation    |  Tranformed RMSLE  |\n",
      "+------------------+--------------------+----------------------+--------------------+\n",
      "|      佣金率      | 0.9269365456880125 |      y_J_佣金率      | 0.920673943679106  |\n",
      "|     带货直播     | 0.9275121709841038 |    sqrt_带货直播     | 0.9273002677718882 |\n",
      "|      粉丝数      | 0.9209335446634087 |    log_sqrt粉丝数    | 0.8741269418279023 |\n",
      "|   销售额_编码    | 0.9279531492504928 |     销售额_编码      | 0.9279531492504928 |\n",
      "|    销量_编码     | 0.7772481409383141 |    pow_销量_编码     | 0.7772149284097957 |\n",
      "| 直播销售额_编码  |  0.92792560690561  |   直播销售额_编码    |  0.92792560690561  |\n",
      "|  直播销量_编码   | 0.7775705465874204 |  pow_直播销量_编码   | 0.7775689539406347 |\n",
      "|   上架距今(天)   | 0.9271122577938844 |   y_J_上架距今(天)   | 0.8951594421068375 |\n",
      "|     视频热度     | 0.9056555757376117 |     y_J_视频热度     | 0.8889651415987346 |\n",
      "|      互动量      | 0.9275786718558019 |     bx_cx_互动量     | 0.8743588906940781 |\n",
      "|      互动率      | 0.9012256578196455 |     bx_cx_互动率     | 0.8750640447131891 |\n",
      "|      tsne_x      | 0.9190938803888695 |     pow2_tsne_x      | 0.9170301353231677 |\n",
      "|      tsne_y      | 0.9270312792148984 |        tsne_y        | 0.9270312792148984 |\n",
      "| 商品价格最大差值 | 0.9270312792148984 |   商品价格最大差值   | 0.9270312792148984 |\n",
      "|  商品价格中位数  | 0.9275124626493639 | bx_cx_商品价格中位数 | 0.7586944458789306 |\n",
      "+------------------+--------------------+----------------------+--------------------+\n",
      "overall best CV RMSLE score:  0.7586944458789306\n"
     ]
    }
   ],
   "source": [
    "train, test= transformer(train, test,cont_cols, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57005c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+--------------------+\n",
      "|        Cluster WOE Feature         |  RMSLE (CV-TRAIN)  |\n",
      "+------------------------------------+--------------------+\n",
      "|      佣金率_unimp_cluster_WOE      | 0.9270312792148984 |\n",
      "|     带货直播_unimp_cluster_WOE     | 0.9270312792148984 |\n",
      "|      粉丝数_unimp_cluster_WOE      | 0.9151541318465167 |\n",
      "|   销售额_编码_unimp_cluster_WOE    | 0.9270312792148984 |\n",
      "|    销量_编码_unimp_cluster_WOE     | 0.8702652995333366 |\n",
      "| 直播销售额_编码_unimp_cluster_WOE  | 0.9270312792148984 |\n",
      "|  直播销量_编码_unimp_cluster_WOE   |  0.96815523968507  |\n",
      "|   上架距今(天)_unimp_cluster_WOE   | 0.9270312792148984 |\n",
      "|     视频热度_unimp_cluster_WOE     | 0.9120828290884176 |\n",
      "|      互动量_unimp_cluster_WOE      | 0.8790859121819199 |\n",
      "|      互动率_unimp_cluster_WOE      | 0.9007640898759744 |\n",
      "|      tsne_x_unimp_cluster_WOE      | 0.9270312792148984 |\n",
      "|      tsne_y_unimp_cluster_WOE      | 0.9270312792148984 |\n",
      "| 商品价格最大差值_unimp_cluster_WOE | 0.9270312792148984 |\n",
      "|  商品价格中位数_unimp_cluster_WOE  | 0.9270312792148984 |\n",
      "+------------------------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Cluster WOE Feature', 'RMSLE (CV-TRAIN)']\n",
    "for col in cont_cols:\n",
    "    sub_set=[f for f in unimportant_features if col in f]\n",
    "#     print(sub_set)\n",
    "    temp_train=train[sub_set]\n",
    "    temp_test=test[sub_set]\n",
    "    sc=StandardScaler()\n",
    "    temp_train=sc.fit_transform(temp_train)\n",
    "    temp_test=sc.transform(temp_test)\n",
    "    model = KMeans()\n",
    "\n",
    "    # print(ideal_clusters)\n",
    "    kmeans = KMeans(n_clusters=5, n_init=10)\n",
    "    kmeans.fit(np.array(temp_train))\n",
    "    labels_train = kmeans.labels_\n",
    "\n",
    "    train[col+\"_unimp_cluster_WOE\"] = labels_train\n",
    "    test[col+\"_unimp_cluster_WOE\"] = kmeans.predict(np.array(temp_test))\n",
    "    \n",
    "    kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    X=train[[col+\"_unimp_cluster_WOE\"]].values\n",
    "    y=train[target].values\n",
    "\n",
    "    best_rmse=[]\n",
    "    for train_idx, val_idx in kf.split(X,y):\n",
    "        X_train,y_train=X[train_idx],y[train_idx]\n",
    "        x_val,y_val=X[val_idx],y[val_idx]\n",
    "        model=LinearRegression()\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred=nearest(model.predict(x_val))\n",
    "        best_rmse.append(rmse(y_val,y_pred))\n",
    "        \n",
    "    table.add_row([col+\"_unimp_cluster_WOE\",np.mean(best_rmse)])\n",
    "    \n",
    "    if overall_best_score<np.mean(best_rmse):\n",
    "            overall_best_score=np.mean(best_rmse)\n",
    "            overall_best_col=col+\"_unimp_cluster_WOE\"\n",
    "    \n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f4a21",
   "metadata": {},
   "source": [
    "# 2.Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caf9a2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_similarity    6\n",
      "cluster_kmeans        6\n",
      "cluster_dbscan        5\n",
      "cluster_hdbscan       6\n",
      "销售均价最大差值              6\n",
      "销售均价分位数               4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [f for f in test.columns if (train[f].dtype != 'O' and train[f].nunique()<20 and train[f].nunique()>2 and \"WOE\" not in f) or (train[f].dtype == 'O') ]\n",
    "print(train[cat_cols].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "061e5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_val(target):\n",
    "    return min(common, key=lambda x: abs(x - target))\n",
    "\n",
    "cat_cols_updated=[]\n",
    "for col in cat_cols:\n",
    "    if train[col].dtype!=\"O\":\n",
    "#         train[f\"{col}_cat\"]=train[col]\n",
    "#         test[f\"{col}_cat\"]=test[col]\n",
    "        cat_cols_updated.append(f\"{col}\")\n",
    "        uncommon=list((set(test[col].unique())| set(train[col].unique()))-(set(test[col].unique())& set(train[col].unique())))\n",
    "        if uncommon:\n",
    "            print('uncommon found')\n",
    "            common=list(set(test[col].unique())& set(train[col].unique()))\n",
    "            train[f\"{col}_cat\"]=train[col].apply(nearest_val)\n",
    "            test[f\"{col}_cat\"]=test[col].apply(nearest_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb72a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Encoding Completed! Test index is preserved.\n",
      "✅ test_encoded index is correctly aligned with test.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def OHE(train_df, test_df, cols, target):\n",
    "    '''\n",
    "    Function for One-Hot Encoding (OHE). Combines train & test to ensure no missing categories.\n",
    "    '''\n",
    "    train_df = train_df.copy()\n",
    "    test_df = test_df.copy()\n",
    "\n",
    "    combined = pd.concat([train_df, test_df], axis=0)  # 合并数据\n",
    "    original_test_index = test_df.index  # 记录 test 原始索引\n",
    "\n",
    "    for col in cols:\n",
    "        combined[col] = combined[col].astype(str).str.replace(\".0\", \"\", regex=False)  # 处理浮点数\n",
    "\n",
    "        # 自定义 One-Hot 编码列名格式\n",
    "        one_hot = pd.get_dummies(combined[col], dtype=int)\n",
    "        one_hot.columns = [str(value) + \"_\" + \"_OHE\" for value in one_hot.columns]\n",
    "\n",
    "        combined = pd.concat([combined, one_hot], axis=1)\n",
    "#         combined.drop(columns=[col], inplace=True)  # 删除原始分类列\n",
    "    \n",
    "    # 重新拆分 train 和 test，确保索引一致\n",
    "    train_ohe = combined.iloc[:len(train_df)].copy()\n",
    "    test_ohe = combined.iloc[len(train_df):].copy()\n",
    "\n",
    "    # 还原 test 原始索引，防止索引对不上的问题\n",
    "    test_ohe.index = original_test_index  \n",
    "\n",
    "    # 确保不误删 target（目标列在 test 里一般不存在）\n",
    "    test_ohe.drop(columns=[target], errors=\"ignore\", inplace=True)\n",
    "    \n",
    "    return train_ohe, test_ohe\n",
    "\n",
    "def high_freq_ohe(train, test, extra_cols, target, n_limit=50):\n",
    "    '''\n",
    "    One-Hot Encoding for high-cardinality categorical variables. Keeps only top `n_limit` categories.\n",
    "    '''\n",
    "    train_copy = train.copy()\n",
    "    test_copy = test.copy()\n",
    "    original_test_index = test.index  # 记录 test 原始索引\n",
    "    \n",
    "    for col in extra_cols:\n",
    "        counts = train_copy[col].value_counts().to_dict()\n",
    "        sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        rare_keys = [key for key, _ in sorted_counts[n_limit:]]  # 低频类别\n",
    "        rare_key_map = dict(zip(rare_keys, [9999] * len(rare_keys)))\n",
    "\n",
    "        train_copy[col] = train_copy[col].replace(rare_key_map)\n",
    "        test_copy[col] = test_copy[col].replace(rare_key_map)\n",
    "\n",
    "    train_copy, test_copy = OHE(train_copy, test_copy, extra_cols, target)\n",
    "\n",
    "    # 确保 test_copy 的索引不变\n",
    "    test_copy.index = original_test_index  \n",
    "\n",
    "    # 移除无信息量列（避免数据错位）\n",
    "    drop_cols = [col for col in train_copy.columns if \"9999\" in col or train_copy[col].nunique() == 1]\n",
    "    train_copy.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "    test_copy.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return train_copy, test_copy\n",
    "\n",
    "def cat_encoding(train, test, cat_cols_updated, target):\n",
    "    '''\n",
    "    Encodes categorical features using OHE, High-Frequency Encoding, and count features.\n",
    "    '''\n",
    "    global overall_best_score\n",
    "    global overall_best_col\n",
    "\n",
    "    train_copy = train.copy()\n",
    "    test_copy = test.copy()\n",
    "    original_test_index = test.index  # 记录 test 原始索引\n",
    "    \n",
    "    for feature in cat_cols_updated:\n",
    "        # 选择编码方式\n",
    "        if train_copy[feature].nunique() <= 15:\n",
    "            train_copy[feature] = train_copy[feature].astype(str) + \"_\" + feature\n",
    "            test_copy[feature] = test_copy[feature].astype(str) + \"_\" + feature\n",
    "            train_copy, test_copy = OHE(train_copy, test_copy, [feature], target)\n",
    "        else:\n",
    "            train_copy, test_copy = high_freq_ohe(train_copy, test_copy, [feature], target, n_limit=15)\n",
    "\n",
    "        # 生成 count 统计特征\n",
    "        counts = train[feature].value_counts().to_dict()\n",
    "#         train_copy[feature + \"_counts\"] = train[feature].map(counts)\n",
    "#         test_copy[feature + \"_counts\"] = test[feature].map(counts)\n",
    "\n",
    "        # 生成 count_rank 特征（频次排名）\n",
    "        list1 = np.arange(len(counts.values()))  # Higher rank for low count\n",
    "        count_rank = dict(zip(list(counts.keys()), list1))\n",
    "        train_copy[feature + \"_count_label\"] = train[feature].replace(count_rank).astype(float)\n",
    "        test_copy[feature + \"_count_label\"] = test[feature].replace(count_rank).astype(float)\n",
    "\n",
    "        temp_cols = [feature + \"_counts\", feature + \"_count_label\"]\n",
    "\n",
    "        train_copy.drop(columns=[feature], inplace=True)\n",
    "        test_copy.drop(columns=[feature], inplace=True)\n",
    "\n",
    "        # 确保 test_copy 索引不变\n",
    "        test_copy.index = original_test_index  \n",
    "\n",
    "    print(\"✅ Encoding Completed! Test index is preserved.\")\n",
    "\n",
    "    return train_copy, test_copy\n",
    "\n",
    "# 运行修正后的代码\n",
    "train_encoded, test_encoded = cat_encoding(train, test, cat_cols_updated, target)\n",
    "\n",
    "# 最后检查索引是否匹配\n",
    "assert test_encoded.index.equals(test.index), \"❌ Error: test_encoded index does not match test index!\"\n",
    "print(\"✅ test_encoded index is correctly aligned with test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c131600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>佣金率</th>\n",
       "      <th>带货视频</th>\n",
       "      <th>带货直播</th>\n",
       "      <th>粉丝数</th>\n",
       "      <th>销售额_编码</th>\n",
       "      <th>销量_编码</th>\n",
       "      <th>直播销售额_编码</th>\n",
       "      <th>直播销量_编码</th>\n",
       "      <th>上架距今(天)</th>\n",
       "      <th>视频热度</th>\n",
       "      <th>...</th>\n",
       "      <th>10_销售均价最大差值__OHE</th>\n",
       "      <th>200_销售均价最大差值__OHE</th>\n",
       "      <th>40_销售均价最大差值__OHE</th>\n",
       "      <th>50_销售均价最大差值__OHE</th>\n",
       "      <th>销售均价最大差值_count_label</th>\n",
       "      <th>per0-10_销售均价分位数__OHE</th>\n",
       "      <th>per10-30_销售均价分位数__OHE</th>\n",
       "      <th>per30-60_销售均价分位数__OHE</th>\n",
       "      <th>per60-100_销售均价分位数__OHE</th>\n",
       "      <th>销售均价分位数_count_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17097</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.152625</td>\n",
       "      <td>0.258556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125240</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.559982</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.559982</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.169719</td>\n",
       "      <td>0.439878</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.421022</td>\n",
       "      <td>0.050061</td>\n",
       "      <td>0.380797</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.308830</td>\n",
       "      <td>0.039962</td>\n",
       "      <td>0.052582</td>\n",
       "      <td>0.039962</td>\n",
       "      <td>0.052582</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.769070</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631</th>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.368388</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.368388</td>\n",
       "      <td>0.166056</td>\n",
       "      <td>0.149923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12154</th>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.124045</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.526291</td>\n",
       "      <td>0.679987</td>\n",
       "      <td>0.526291</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.560012</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21953</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.076566</td>\n",
       "      <td>0.399976</td>\n",
       "      <td>0.210485</td>\n",
       "      <td>0.399976</td>\n",
       "      <td>0.210485</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.322251</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>0.018036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.719989</td>\n",
       "      <td>0.473657</td>\n",
       "      <td>0.719989</td>\n",
       "      <td>0.473657</td>\n",
       "      <td>0.177656</td>\n",
       "      <td>0.149923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0.298597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.004201</td>\n",
       "      <td>0.359974</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.359974</td>\n",
       "      <td>0.105216</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.114902</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16093</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.032270</td>\n",
       "      <td>0.559982</td>\n",
       "      <td>0.578925</td>\n",
       "      <td>0.559982</td>\n",
       "      <td>0.578925</td>\n",
       "      <td>0.080586</td>\n",
       "      <td>0.641097</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20081 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            佣金率  带货视频      带货直播       粉丝数    销售额_编码     销量_编码  直播销售额_编码  \\\n",
       "17097  0.000000   0.0  0.004816  0.027537  0.679987  0.421022  0.679987   \n",
       "7673   0.000000   0.0  0.125240  0.000140  0.559982  0.105216  0.559982   \n",
       "4175   0.000000   0.0  0.000962  0.052342  0.679987  0.421022  0.679987   \n",
       "9379   0.000000   0.0  0.005779  0.308830  0.039962  0.052582  0.039962   \n",
       "5631   0.018036   0.0  0.000962  0.007297  0.679987  0.368388  0.679987   \n",
       "...         ...   ...       ...       ...       ...       ...       ...   \n",
       "12154  0.018036   0.0  0.000962  0.124045  0.679987  0.526291  0.679987   \n",
       "21953  0.000000   0.0  0.011560  0.076566  0.399976  0.210485  0.399976   \n",
       "5536   0.018036   0.0  0.003853  0.007297  0.719989  0.473657  0.719989   \n",
       "896    0.298597   0.0  0.001926  0.004201  0.359974  0.105216  0.359974   \n",
       "16093  0.000000   0.0  0.005779  0.032270  0.559982  0.578925  0.559982   \n",
       "\n",
       "        直播销量_编码   上架距今(天)      视频热度  ...  10_销售均价最大差值__OHE  200_销售均价最大差值__OHE  \\\n",
       "17097  0.421022  0.152625  0.258556  ...                 0                  0   \n",
       "7673   0.105216  0.169719  0.439878  ...                 0                  1   \n",
       "4175   0.421022  0.050061  0.380797  ...                 0                  0   \n",
       "9379   0.052582  0.854701  0.769070  ...                 0                  0   \n",
       "5631   0.368388  0.166056  0.149923  ...                 0                  0   \n",
       "...         ...       ...       ...  ...               ...                ...   \n",
       "12154  0.526291  0.111111  0.560012  ...                 0                  0   \n",
       "21953  0.210485  0.111111  0.322251  ...                 0                  0   \n",
       "5536   0.473657  0.177656  0.149923  ...                 0                  0   \n",
       "896    0.105216  0.119658  0.114902  ...                 0                  0   \n",
       "16093  0.578925  0.080586  0.641097  ...                 0                  0   \n",
       "\n",
       "       40_销售均价最大差值__OHE  50_销售均价最大差值__OHE  销售均价最大差值_count_label  \\\n",
       "17097                 0                 0                   0.0   \n",
       "7673                  0                 0                   1.0   \n",
       "4175                  0                 0                   0.0   \n",
       "9379                  0                 1                   2.0   \n",
       "5631                  0                 0                   0.0   \n",
       "...                 ...               ...                   ...   \n",
       "12154                 0                 0                   0.0   \n",
       "21953                 0                 1                   2.0   \n",
       "5536                  0                 0                   0.0   \n",
       "896                   0                 0                   0.0   \n",
       "16093                 1                 0                   3.0   \n",
       "\n",
       "       per0-10_销售均价分位数__OHE  per10-30_销售均价分位数__OHE  per30-60_销售均价分位数__OHE  \\\n",
       "17097                     0                      1                      0   \n",
       "7673                      1                      0                      0   \n",
       "4175                      0                      0                      1   \n",
       "9379                      0                      0                      0   \n",
       "5631                      0                      1                      0   \n",
       "...                     ...                    ...                    ...   \n",
       "12154                     0                      0                      0   \n",
       "21953                     0                      0                      0   \n",
       "5536                      0                      1                      0   \n",
       "896                       0                      0                      0   \n",
       "16093                     0                      0                      0   \n",
       "\n",
       "       per60-100_销售均价分位数__OHE  销售均价分位数_count_label  \n",
       "17097                       0                  2.0  \n",
       "7673                        0                  3.0  \n",
       "4175                        0                  1.0  \n",
       "9379                        1                  0.0  \n",
       "5631                        0                  2.0  \n",
       "...                       ...                  ...  \n",
       "12154                       1                  0.0  \n",
       "21953                       1                  0.0  \n",
       "5536                        0                  2.0  \n",
       "896                         1                  0.0  \n",
       "16093                       1                  0.0  \n",
       "\n",
       "[20081 rows x 178 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9942a0a",
   "metadata": {},
   "source": [
    "# 3.Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83283455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_drop=[ f for f in unimportant_features if f in train.columns and 'log' not in f]\n",
    "first_drop=[ f for f in unimportant_features if f in train.columns ]\n",
    "train=train_encoded.drop(columns=first_drop)\n",
    "test=test_encoded.drop(columns=first_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42f1d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_drop_list=[]\n",
    "\n",
    "# table = PrettyTable()\n",
    "# table.field_names = ['Original', 'Final Transformation', \"RMSLE(CV)- Regression\"]\n",
    "# dt_params={'criterion': 'absolute_error'}\n",
    "# threshold=0.5\n",
    "# # It is possible that multiple parent features share same child features, so store selected features to avoid selecting the same feature again\n",
    "# best_cols=[]\n",
    "\n",
    "# def correlation_elimination(train,test):\n",
    "#     for col in cont_cols:\n",
    "#         sub_set=[f for f in train.columns if col in f and train[f].nunique()>100]\n",
    "#         print(sub_set)\n",
    "#         if len(sub_set)>2:\n",
    "#             correlated_features = []\n",
    "\n",
    "#             for i, feature in enumerate(sub_set):\n",
    "#                 # Check correlation with all remaining features\n",
    "#                 for j in range(i+1, len(sub_set)):\n",
    "#                     correlation = np.abs(train[feature].corr(train[sub_set[j]]))\n",
    "#                     # If correlation is greater than threshold, add to list of highly correlated features\n",
    "#                     if correlation > threshold:\n",
    "#                         correlated_features.append(sub_set[j])\n",
    "\n",
    "#             # Remove duplicate features from the list\n",
    "#             correlated_features = list(set(correlated_features))\n",
    "#             print(correlated_features)\n",
    "#             if len(correlated_features)>=2:\n",
    "\n",
    "#                 temp_train=train[correlated_features]\n",
    "#                 temp_test=test[correlated_features]\n",
    "\n",
    "#                 #Scale before applying PCA\n",
    "#                 sc=StandardScaler()\n",
    "#                 temp_train=sc.fit_transform(temp_train)\n",
    "#                 temp_test=sc.transform(temp_test)\n",
    "#                 # Initiate PCA\n",
    "#                 pca=TruncatedSVD(n_components=1)\n",
    "#                 x_pca_train=pca.fit_transform(temp_train)\n",
    "#                 x_pca_test=pca.transform(temp_test)\n",
    "#                 x_pca_train=pd.DataFrame(x_pca_train, columns=[col+\"_pca_comb_final\"])\n",
    "#                 x_pca_test=pd.DataFrame(x_pca_test, columns=[col+\"_pca_comb_final\"])\n",
    "#                 train=pd.concat([train,x_pca_train],axis='columns')\n",
    "#                 test=pd.concat([test,x_pca_test],axis='columns')\n",
    "\n",
    "#                 # Clustering\n",
    "#                 model = KMeans()\n",
    "#                 kmeans = KMeans(n_clusters=28)\n",
    "#                 kmeans.fit(np.array(temp_train))  # 训练模型\n",
    "\n",
    "#                 # 使用训练好的kmeans模型对test数据进行预测\n",
    "#                 test[col+'_final_cluster'] = kmeans.predict(np.array(temp_test))  # 确保test数据有相同的特征\n",
    "\n",
    "#                 # 计算类别均值并映射到train和test\n",
    "#                 cat_labels = train.groupby([col+\"_final_cluster\"])[target].mean()\n",
    "#                 cat_labels2 = cat_labels.to_dict()\n",
    "\n",
    "#                 # 将聚类标签映射为目标变量的均值\n",
    "#                 train[col+\"_final_cluster\"] = train[col+\"_final_cluster\"].map(cat_labels2)\n",
    "#                 test[col+\"_final_cluster\"] = test[col+\"_final_cluster\"].map(cat_labels2)\n",
    "\n",
    "#                 correlated_features=correlated_features+[col+\"_pca_comb_final\",col+\"_final_cluster\"]\n",
    "#                 # See which transformation along with the original is giving you the best univariate fit with target\n",
    "#                 kf=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#                 rmse_scores = []\n",
    "\n",
    "#                 for f in temp_cols:\n",
    "#                     X = train_copy[[f]].values\n",
    "#                     y = train_copy[target].astype(int).values\n",
    "\n",
    "#                     rmses = []\n",
    "#                     for train_idx, val_idx in kf.split(X, y):\n",
    "#                         X_train, y_train = X[train_idx], y[train_idx]\n",
    "#                         x_val, y_val = X[val_idx], y[val_idx]\n",
    "#                         model=LinearRegression()\n",
    "#                         model.fit(X_train,y_train)\n",
    "#                         y_pred=nearest(model.predict(x_val))\n",
    "#                         rmses.append(rmse(y_val,y_pred))\n",
    "\n",
    "#                     if f not in best_cols:\n",
    "#                         rmse_scores.append((f,np.mean(rmses)))\n",
    "#                 best_col, best_rmse=sorted(rmse_scores, key=lambda x:x[1], reverse=False)[0]\n",
    "#                 best_cols.append(best_col)\n",
    "\n",
    "#                 cols_to_drop = [f for f in correlated_features if  f not in best_cols]\n",
    "#                 if cols_to_drop:\n",
    "#                     final_drop_list=final_drop_list+cols_to_drop\n",
    "#                 table.add_row([col,best_col ,best_acc])\n",
    "\n",
    "#     print(table)\n",
    "# correlation_elimination(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d810286",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features=[f for f in train.columns if f not in [target]]\n",
    "final_features=[*set(final_features)]\n",
    "final_features_cont = [f for f in final_features if ('OHE' not in f and 'count_label' not in f)]\n",
    "# final_features_cont\n",
    "sc=StandardScaler()\n",
    "\n",
    "train_scaled=train.copy()\n",
    "test_scaled=test.copy()\n",
    "train_scaled[final_features_cont]=sc.fit_transform(train[final_features_cont])\n",
    "test_scaled[final_features_cont]=sc.transform(test[final_features_cont])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c0efb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def post_processor(train, test):\n",
    "#     cols=train.drop(columns=[target]).columns\n",
    "#     train_cop=train.copy()\n",
    "#     test_cop=test.copy()\n",
    "#     drop_cols=[]\n",
    "#     for i, feature in enumerate(cols):\n",
    "#         for j in range(i+1, len(cols)):\n",
    "#             if sum(abs(train_cop[feature]-train_cop[cols[j]]))==0:\n",
    "#                 if cols[j] not in drop_cols:\n",
    "#                     drop_cols.append(cols[j])\n",
    "#     print(drop_cols)\n",
    "#     train_cop.drop(columns=drop_cols,inplace=True)\n",
    "#     test_cop.drop(columns=drop_cols,inplace=True)\n",
    "    \n",
    "#     return train_cop, test_cop\n",
    "                    \n",
    "# train_cop, test_cop= post_processor(train_scaled, test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97663001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected Potential outliers: 201\n",
      "(19880, 73)\n",
      "Number of detected Potential outliers: 199\n",
      "(19681, 73)\n",
      "Number of detected Potential outliers: 41\n",
      "(19640, 73)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=train_scaled\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def isolation_forest(data):\n",
    "    data_pure=data.copy()\n",
    "    \n",
    "#     model = IsolationForest(contamination=0.010650427383702971, random_state=0)\n",
    "    model = IsolationForest(contamination=0.01, random_state=0)\n",
    "    \n",
    "    drop_cols=[f for f in data_pure.columns if f in target]\n",
    "    model.fit(data_pure.drop(columns=drop_cols))\n",
    "\n",
    "    # Predict the anomaly scores for each data point\n",
    "    anomalies = model.predict(data_pure.drop(columns=drop_cols))\n",
    "\n",
    "    outliers = anomalies == -1\n",
    "\n",
    "    # Combine the outlier information with the original data and labels\n",
    "    data_pure['outlier_ISF'] = outliers\n",
    "\n",
    "    # Print the identified outliers\n",
    "    identified_outliers = data_pure[data_pure['outlier_ISF']]\n",
    "    print(f\"Number of detected Potential outliers: {identified_outliers.shape[0]}\")\n",
    "    \n",
    "    data_clean=data[~data_pure['outlier_ISF']]\n",
    "    print(data_clean.shape)\n",
    "    \n",
    "    return data_clean\n",
    "\n",
    "\n",
    "data_clean=isolation_forest(data).reset_index(drop=True)\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "params={'n_neighbors': 13, 'contamination': 0.01}\n",
    "\n",
    "def lof(data):\n",
    "    data_pure=data.copy()\n",
    "    drop_cols=[f for f in data_pure.columns if f in target]\n",
    "\n",
    "    features = data_pure.drop(columns=drop_cols)\n",
    "    lof = LocalOutlierFactor(**params)  # Adjust contamination based on your data\n",
    "    anomalies = lof.fit_predict(features)  # Negative scores are outliers\n",
    "\n",
    "    outliers = anomalies == -1\n",
    "\n",
    "    # Combine the outlier information with the original data and labels\n",
    "    data_pure['outliers_LOF'] = outliers\n",
    "\n",
    "    # Print the identified outliers\n",
    "    identified_outliers = data_pure[data_pure['outliers_LOF']]\n",
    "    print(f\"Number of detected Potential outliers: {identified_outliers.shape[0]}\")\n",
    "    \n",
    "    data_clean=data[~data_pure['outliers_LOF']]\n",
    "    print(data_clean.shape)\n",
    "    \n",
    "    return data_clean\n",
    "\n",
    "data_clean=lof(data_clean).reset_index(drop=True)\n",
    "\n",
    "def pca_anamolies(data):\n",
    "    data_pure=data.copy()\n",
    "    drop_cols=[f for f in data_pure.columns if f in target]\n",
    "\n",
    "    features = data_pure.drop(columns=drop_cols)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "    pca = PCA(n_components=2)  # Choose the number of components for visualization\n",
    "    principal_components = pca.fit_transform(scaled_features)\n",
    "\n",
    "    # Calculate the reconstruction error (MSE) for each data point\n",
    "    reconstruction_errors = ((scaled_features - pca.inverse_transform(principal_components)) ** 2).mean(axis=1)\n",
    "\n",
    "    # Set a threshold for anomaly detection\n",
    "    threshold = 2.5 # Adjust the threshold based on your data and desired sensitivity\n",
    "\n",
    "    # Identify potential outliers\n",
    "    potential_outliers = [index for index, error in enumerate(reconstruction_errors) if error > threshold]\n",
    "\n",
    "    # Create a new column 'outliers' in the DataFrame\n",
    "    data_pure['outliers_PCA'] = False\n",
    "    data_pure.loc[potential_outliers, 'outliers_PCA'] = True\n",
    "\n",
    "    print(f\"Number of detected Potential outliers: {len(potential_outliers)}\")\n",
    "    \n",
    "    data_clean=data[~data_pure['outliers_PCA']]\n",
    "    print(data_clean.shape)\n",
    "\n",
    "    # Plot the data with potential outliers highlighted\n",
    "    plt.scatter(principal_components[:, 0], principal_components[:, 1], c='green', label='Normal Data')\n",
    "    plt.scatter(principal_components[potential_outliers, 0], principal_components[potential_outliers, 1], c='red', label='Potential Outliers')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.legend()\n",
    "    plt.title('PCA with Potential Outliers')\n",
    "    plt.show()\n",
    "    return data_clean\n",
    "\n",
    "data_clean=pca_anamolies(data_clean).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1289b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_clean.drop(columns=[target])\n",
    "y_train = data_clean[target]\n",
    "X_test = test_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520200e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import  CatBoostRegressor \n",
    "import xgboost as xgb\n",
    "# !pip install lightgbm --install-option=--gpu --install-option=\"--boost-root=C:/local/boost_1_69_0\" --install-option=\"--boost-librarydir=C:/local/boost_1_69_0/lib64-msvc-14.1\"\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "def get_most_important_features(X_train, y_train, n,model_input):\n",
    "    \n",
    "    lgb_params = {\n",
    "            'n_estimators': 100,\n",
    "            'max_depth': 6,\n",
    "            \"num_leaves\": 16,\n",
    "            'learning_rate': 0.05,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.8,\n",
    "            #'reg_alpha': 0.25,\n",
    "            'reg_lambda': 5e-07,\n",
    "            'objective': 'regression_l2',\n",
    "            'metric': 'mean_absolute_error',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'random_state': 42,\n",
    "            'verbose':-1\n",
    "        }\n",
    "    cb_params = {\n",
    "            'iterations': 300,\n",
    "            'depth': 6,\n",
    "            'learning_rate': 0.01,\n",
    "            'l2_leaf_reg': 0.5,\n",
    "            'random_strength': 0.2,\n",
    "            'max_bin': 150,\n",
    "            'od_wait': 80,\n",
    "            'one_hot_max_size': 70,\n",
    "            'grow_policy': 'Depthwise',\n",
    "            'bootstrap_type': 'Bayesian',\n",
    "            'od_type': 'IncToDec',\n",
    "            'eval_metric': 'MSLE',\n",
    "            'loss_function': 'RMSE',\n",
    "            'random_state': 42,\n",
    "             'verbose':False\n",
    "        }\n",
    "     \n",
    "    xgb_params = {\n",
    "            'n_estimators': 500,\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.0116,\n",
    "            'colsample_bytree': 1,\n",
    "            'min_child_weight': 9,\n",
    "            'n_jobs': -1,\n",
    "            'eval_metric': 'rmsle',\n",
    "            'objective': \"reg:squarederror\",\n",
    "            'tree_method': 'hist',\n",
    "            'verbosity': 0,\n",
    "            'random_state': 42,\n",
    "        }\n",
    "    if 'xgb' in model_input:\n",
    "        model = xgb.XGBRegressor(**xgb_params)\n",
    "    elif 'cat' in model_input:\n",
    "        model=CatBoostRegressor(**cb_params)\n",
    "    else:\n",
    "        model=lgb.LGBMRegressor(**lgb_params)\n",
    "    \n",
    "    \n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train,y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        \n",
    "        if 'lgb' in model_input:\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "        else:\n",
    "            model.fit(X_train_fold,y_train_fold,verbose=False)\n",
    "\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "\n",
    "        rmses = np.sqrt(mean_squared_error(y_val_fold,y_pred))\n",
    "        rmse_scores.append(rmses)\n",
    "\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "\n",
    "    feature_importance_list = [(X_train.columns[i], importance) for i, importance in enumerate(feature_importances)]\n",
    "\n",
    "    sorted_features = sorted(feature_importance_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_n_features = [feature[0] for feature in sorted_features[:n]]\n",
    "    print(avg_rmse)\n",
    "    return top_n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c57f2160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5494800094284074\n",
      "0.5204397424452301\n",
      "0.5461690587622847\n"
     ]
    }
   ],
   "source": [
    "n_imp_features_cat=get_most_important_features(X_train.reset_index(drop=True), y_train,round(len(final_features)*3/4), 'cat')\n",
    "n_imp_features_xgb=get_most_important_features(X_train.reset_index(drop=True), y_train,round(len(final_features)*3/4), 'xgb')\n",
    "n_imp_features_lgbm=get_most_important_features(X_train.reset_index(drop=True), y_train,round(len(final_features)*3/4), 'lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "159b0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 features have been selected from three algorithms for the final model\n"
     ]
    }
   ],
   "source": [
    "n_imp_features=[*set(n_imp_features_lgbm+n_imp_features_cat+n_imp_features_xgb)]\n",
    "print(f\"{len(n_imp_features)} features have been selected from three algorithms for the final model\")\n",
    "\n",
    "X_train=X_train[n_imp_features]\n",
    "X_test=X_test[n_imp_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcaefb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final_train = pd.concat([X_train,y_train],axis=1)\n",
    "data_final_train.to_csv(f'./train_test_data/data_final_train_{len(n_imp_features)}_features.csv',index=False)\n",
    "\n",
    "data_final_test = pd.concat([X_test,y_test],axis=1)\n",
    "data_final_test.to_csv(f'./train_test_data/data_final_test_{len(n_imp_features)}_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f8a5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (transformer_git)",
   "language": "python",
   "name": "transformer_git"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
